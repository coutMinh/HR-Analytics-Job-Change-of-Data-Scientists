{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HR Analytics - Data Preprocessing Pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src folder to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_processing import (\n",
    "    preprocess_train_dataset, \n",
    "    preprocess_test_dataset,\n",
    "    save_processed_data\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Preprocess Training Data\n",
    "\n",
    "Xử lý training data và lưu artifacts (statistics, categories) để sử dụng cho test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING TRAINING DATA\n",
      "Loading ../data/raw/aug_train.csv...\n",
      "  19,158 samples\n",
      "Standardizing numeric features...\n",
      "Encoding categorical features...\n",
      "One-hot encoding...\n",
      "Engineering features...\n",
      "Building feature matrix...\n",
      "Artifacts → ../data/processed/artifacts.json\n",
      "Done! X: (19158, 33), y: (19158,), features: 33\n",
      "\n",
      "============================================================\n",
      "TRAINING DATA SUMMARY\n",
      "Feature matrix shape: (19158, 33)\n",
      "Target vector shape: (19158,)\n",
      "Number of features: 33\n",
      "\n",
      "Feature names (33 total):\n",
      "   1. cdi_scaled\n",
      "   2. hours_scaled\n",
      "   3. gender\n",
      "   4. rel_exp\n",
      "   5. exp_bin\n",
      "   6. comp_size\n",
      "   7. last_job\n",
      "   8. uni_Full time course\n",
      "   9. uni_Part time course\n",
      "  10. uni_no_enrollment\n",
      "  11. edu_Graduate\n",
      "  12. edu_High School\n",
      "  13. edu_Masters\n",
      "  14. edu_Phd\n",
      "  15. edu_Primary School\n",
      "  16. maj_Arts\n",
      "  17. maj_Business Degree\n",
      "  18. maj_Humanities\n",
      "  19. maj_No Major\n",
      "  20. maj_Other\n",
      "  21. maj_STEM\n",
      "  22. ctype_Early Stage Startup\n",
      "  23. ctype_Funded Startup\n",
      "  24. ctype_NGO\n",
      "  25. ctype_Other\n",
      "  26. ctype_Public Sector\n",
      "  27. ctype_Pvt Ltd\n",
      "  28. exp_relevance\n",
      "  29. company_stability\n",
      "  30. gender_missing\n",
      "  31. experience_bin_missing\n",
      "  32. company_size_missing\n",
      "  33. last_new_job_missing\n",
      "\n",
      "Data quality check:\n",
      "  NaN values in X: 0\n",
      "  Inf values in X: 0\n",
      "  NaN values in y: 0\n",
      "\n",
      "Target distribution:\n",
      "  Class 0: 14381 (75.1%)\n",
      "  Class 1:  4777 (24.9%)\n"
     ]
    }
   ],
   "source": [
    "train_raw_path = '../data/raw/aug_train.csv'\n",
    "artifacts_path = '../data/processed/artifacts.json'\n",
    "train_processed_path = '../data/processed/train_processed.csv'\n",
    "print(\"PREPROCESSING TRAINING DATA\")\n",
    "\n",
    "training_data = preprocess_train_dataset(\n",
    "    filepath=train_raw_path,\n",
    "    save_artifacts=True,\n",
    "    artifacts_path=artifacts_path\n",
    ")\n",
    "\n",
    "X_train = training_data['X']\n",
    "y_train = training_data['y']\n",
    "feature_names = training_data['feature_names']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TRAINING DATA SUMMARY\")\n",
    "print(f\"Feature matrix shape: {X_train.shape}\")\n",
    "print(f\"Target vector shape: {y_train.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "print(f\"\\nFeature names ({len(feature_names)} total):\")\n",
    "for i, name in enumerate(feature_names, 1):\n",
    "    print(f\"  {i:2d}. {name}\")\n",
    "\n",
    "print(f\"\\nData quality check:\")\n",
    "print(f\"  NaN values in X: {np.isnan(X_train).sum()}\")\n",
    "print(f\"  Inf values in X: {np.isinf(X_train).sum()}\")\n",
    "print(f\"  NaN values in y: {np.isnan(y_train).sum()}\")\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(f\"\\nTarget distribution:\")\n",
    "for val, count in zip(unique, counts):\n",
    "    pct = 100 * count / len(y_train)\n",
    "    print(f\"  Class {int(val)}: {count:5d} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Save Training Data\n",
    "\n",
    "Lưu processed training data thành CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed training data...\n",
      "Saved ../data/processed/train_processed.csv ((19158, 34))\n",
      "Training data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving processed training data...\")\n",
    "save_processed_data(\n",
    "    X=X_train, \n",
    "    y=y_train, \n",
    "    feature_names=feature_names,\n",
    "    filepath=train_processed_path\n",
    ")\n",
    "print(f\"Training data saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Preprocess Test Data\n",
    "\n",
    "Xử lý test data sử dụng artifacts từ training (mean, std, categories) để đảm bảo consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREPROCESSING TEST DATA\n",
      "Loading ../data/raw/aug_test.csv...\n",
      "  2,129 samples\n",
      "Standardizing with train stats...\n",
      "Encoding...\n",
      "One-hot encoding...\n",
      "Engineering...\n",
      "Done! X: (2129, 33), expected: 33\n",
      "\n",
      "============================================================\n",
      "TEST DATA SUMMARY\n",
      "Feature matrix shape: (2129, 33)\n",
      "Number of features: 33\n",
      "Enrollee IDs shape: (2129,)\n",
      "\n",
      "Data quality check:\n",
      "  NaN values in X: 0\n",
      "  Inf values in X: 0\n"
     ]
    }
   ],
   "source": [
    "test_raw_path = '../data/raw/aug_test.csv'\n",
    "test_processed_path = '../data/processed/test_processed.csv'\n",
    "print(\"PREPROCESSING TEST DATA\")\n",
    "\n",
    "test_bundle = preprocess_test_dataset(\n",
    "    filepath=test_raw_path,\n",
    "    artifacts_path=artifacts_path\n",
    ")\n",
    "\n",
    "X_test = test_bundle['X']\n",
    "test_feature_names = test_bundle['feature_names']\n",
    "enrollee_ids = test_bundle['enrollee_ids']\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"TEST DATA SUMMARY\")\n",
    "print(f\"Feature matrix shape: {X_test.shape}\")\n",
    "print(f\"Number of features: {len(test_feature_names)}\")\n",
    "print(f\"Enrollee IDs shape: {enrollee_ids.shape}\")\n",
    "print(f\"\\nData quality check:\")\n",
    "print(f\"  NaN values in X: {np.isnan(X_test).sum()}\")\n",
    "print(f\"  Inf values in X: {np.isinf(X_test).sum()}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Save Test Data\n",
    "\n",
    "Lưu processed test data (với enrollee_ids để tạo submission file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving processed test data...\n",
      "Saved ../data/processed/test_processed.csv ((2129, 34))\n",
      "  Test data saved successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving processed test data...\")\n",
    "save_processed_data(\n",
    "    X=X_test, \n",
    "    y=None,  \n",
    "    feature_names=test_feature_names,\n",
    "    filepath=test_processed_path,\n",
    "    enrollee_ids=enrollee_ids\n",
    ")\n",
    "print(f\"  Test data saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
